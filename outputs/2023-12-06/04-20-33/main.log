[2023-12-06 04:20:36,026][flwr][INFO] - Starting Flower simulation, config: ServerConfig(num_rounds=50, round_timeout=None)
[2023-12-06 04:20:40,717][flwr][INFO] - Flower VCE: Ray initialized with resources: {'CPU': 40.0, 'accelerator_type:P100': 1.0, 'node:128.105.144.67': 1.0, 'GPU': 1.0, 'object_store_memory': 59480969625.0, 'memory': 128788929127.0}
[2023-12-06 04:20:40,718][flwr][INFO] - Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
[2023-12-06 04:20:40,718][flwr][INFO] - Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.2}
[2023-12-06 04:20:40,761][flwr][INFO] - Flower VCE: Creating VirtualClientEngineActorPool with 5 actors
[2023-12-06 04:20:40,761][flwr][INFO] - Initializing global parameters
[2023-12-06 04:20:40,761][flwr][INFO] - Requesting initial parameters from one random client
[2023-12-06 04:20:49,030][flwr][INFO] - Received initial parameters from one random client
[2023-12-06 04:20:49,030][flwr][INFO] - Evaluating initial parameters
[2023-12-06 04:20:55,019][flwr][ERROR] - mat1 and mat2 shapes cannot be multiplied (64x4096 and 3136x512)
[2023-12-06 04:20:55,022][flwr][ERROR] - Traceback (most recent call last):
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/flwr/simulation/app.py", line 308, in start_simulation
    hist = run_fl(
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/flwr/server/app.py", line 225, in run_fl
    hist = server.fit(num_rounds=config.num_rounds, timeout=config.round_timeout)
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/flwr/server/server.py", line 92, in fit
    res = self.strategy.evaluate(0, parameters=self.parameters)
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/flwr/server/strategy/fedavg.py", line 163, in evaluate
    eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})
  File "/users/wang2451/Fed_with_flower/utils.py", line 145, in evaluate
    loss, accuracy = model.test(net, testloader, device=device)
  File "/users/wang2451/Fed_with_flower/model.py", line 146, in test
    outputs = net(images)
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/wang2451/Fed_with_flower/model.py", line 47, in forward
    output_tensor = F.relu(self.fc1(output_tensor))
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x4096 and 3136x512)

[2023-12-06 04:20:55,022][flwr][ERROR] - Your simulation crashed :(. This could be because of several reasons.The most common are: 
	 > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.
	 > All the actors in your pool crashed. This could be because: 
		 - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 4, 'num_gpus': 0.2} is not enough for your workload). Use fewer concurrent actors. 
		 - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 4, 'num_gpus': 0.2}.
