[2023-12-04 21:49:28,902][flwr][INFO] - Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2023-12-04 21:49:33,619][flwr][INFO] - Flower VCE: Ray initialized with resources: {'CPU': 40.0, 'accelerator_type:P100': 1.0, 'node:128.105.144.67': 1.0, 'object_store_memory': 59568442982.0, 'GPU': 1.0, 'memory': 128993033626.0}
[2023-12-04 21:49:33,619][flwr][INFO] - Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
[2023-12-04 21:49:33,620][flwr][INFO] - Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.2}
[2023-12-04 21:49:33,654][flwr][INFO] - Flower VCE: Creating VirtualClientEngineActorPool with 5 actors
[2023-12-04 21:49:33,654][flwr][INFO] - Initializing global parameters
[2023-12-04 21:49:33,655][flwr][INFO] - Requesting initial parameters from one random client
[2023-12-04 21:49:39,028][flwr][INFO] - Received initial parameters from one random client
[2023-12-04 21:49:39,029][flwr][INFO] - Evaluating initial parameters
[2023-12-04 21:49:39,496][flwr][ERROR] - index 0 is out of bounds for dimension 0 with size 0
[2023-12-04 21:49:39,499][flwr][ERROR] - Traceback (most recent call last):
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/flwr/simulation/app.py", line 308, in start_simulation
    hist = run_fl(
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/flwr/server/app.py", line 225, in run_fl
    hist = server.fit(num_rounds=config.num_rounds, timeout=config.round_timeout)
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/flwr/server/server.py", line 92, in fit
    res = self.strategy.evaluate(0, parameters=self.parameters)
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/flwr/server/strategy/fedavg.py", line 163, in evaluate
    eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})
  File "/users/wang2451/Fed_with_flower/utils.py", line 128, in evaluate
    net.load_state_dict(state_dict, strict=True)
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2138, in load_state_dict
    load(self, state_dict)
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2126, in load
    load(child, child_state_dict, child_prefix)
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2120, in load
    module._load_from_state_dict(
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py", line 110, in _load_from_state_dict
    super()._load_from_state_dict(
  File "/users/wang2451/miniconda3/envs/flower/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2015, in _load_from_state_dict
    input_param = input_param[0]
IndexError: index 0 is out of bounds for dimension 0 with size 0

[2023-12-04 21:49:39,499][flwr][ERROR] - Your simulation crashed :(. This could be because of several reasons.The most common are: 
	 > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.
	 > All the actors in your pool crashed. This could be because: 
		 - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 4, 'num_gpus': 0.2} is not enough for your workload). Use fewer concurrent actors. 
		 - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 4, 'num_gpus': 0.2}.
